{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "In this example, we will show how to analyze example data using the `SHAPER` framework. In particular, we will show how to load pre-built observables (as defined in https://arxiv.org/pdf/2302.12266.pdf), how to build custom observables, how to evaluate these observables on event data, and how to make plots of the observable distributions.\n",
    "\n",
    "To run this example, it is HIGHLY recommended that you install pyshaper with all available extras -- namely, the `energyflow` and `imageio` packages. This is necessary to load the example dataset and to create gifs automatically, though these are not necessary for ordinary usage of `pyshaper`. This can be easily accomplished with `pip`:\n",
    "\n",
    "`python -m pip install --upgrade 'pyshaper[all]'`\n",
    "\n",
    "Enjoy!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# SHAPER\n",
    "from pyshaper.CommonObservables import buildCommmonObservables\n",
    "from pyshaper.Observables import Observable\n",
    "from pyshaper.Shaper import Shaper\n",
    "\n",
    "# Utils\n",
    "from pyshaper.utils.data_utils import load_cmsopendata\n",
    "from pyshaper.utils.plot_utils import plot_event\n",
    "\n",
    "\n",
    "# Necessary GPU nonsense\n",
    "import torch \n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "    print(\"Using GPU!\")\n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "    print(\"Using CPU!\")\n",
    "device = torch.device(dev) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use CMS opendata as our example dataset. The function `load_cmsopendata` will automatically download and format an example dataset for you in the \"/.energyflow/datasets\" subfolder. This requires the `energyflow` package, but this is only needed for the example dataset. The variable `dataset` is our dataset (representing simulated jets in the CMS detector), and `sim_weights` and `sim_factors` are used for plotting (which we will not need for this example). Of course, feel free to use your own data here. Downloading the `energyflow` dataset for the first time will take approximately 20 minutes. Loading from memory will take approximately 1-2 minutes.\n",
    "\n",
    "The dataset must have the following format for `SHAPER` to work. The variable `dataset` is a PYTHON array. The elements of this array (for instance, `example_event = dataset[0]`) are PYTHON tuples representing individual events. For an event with $N$ particles, the first element of the tuple is a numpy array of shape $(N,2)$ representing the positions of particles in an event, and the second element of the tuple is a numpy array of shape $(N,)$ representing the (normalized) weights of each particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "R = 0.5\n",
    "beta = 1.0\n",
    "N = 50\n",
    "pt_lower = 475\n",
    "pt_upper = 525\n",
    "eta = 1.9\n",
    "quality = 2\n",
    "pad = 125\n",
    "plot_dir = \"results\"\n",
    "\n",
    "# Load data (NOTE: Need the `energyflow` package installed for the default dataset, or provide your own data)\n",
    "dataset, sim_weights, sim_factors = load_cmsopendata(\"~/.energyflow/\", \"sim\", pt_lower, pt_upper, eta, quality, pad, n = N)\n",
    "\n",
    "\n",
    "example_event = dataset[0]\n",
    "plot_event(example_event[0], example_event[1], R, color = \"blue\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Observables\n",
    "\n",
    "There are many predefined observables in the `SHAPER` framework. The function `buildCommonObservables` can be used to access them. To see the list of all pre-built observables, print the dictionary `commonObservables` (if you want a larger $N$, change the `N` parameter from `3`.). For now we will pick out two observables of interest as an example: `_3subjettiness` and `_3diskiness`.\n",
    "\n",
    "Note that the object `pointers` is necessary to retain references to the pre-built observables. Do not delete it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonObservables, pointers = buildCommmonObservables(N = 3, beta = 1, R = R, device = device)\n",
    "_3subjettiness = commonObservables[\"3-Subjettiness\"]\n",
    "_3diskiness= commonObservables[\"3-Diskiness\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom and Composite Observables\n",
    "\n",
    "Now, we will construct some custom shape observables. A shape observable needs three major ingredients:\n",
    "* A sampler function: This is a function that takes in an integer $N$ and a dictionary of parameters. It returns a list of points (usually $N$ of them, but not necessarily) and weights that depend on the parameters and in principle should approximate the shape. The determination of these functions are where the \"science\" occurs.\n",
    "* A list of parameters: Shapes require parameters, which are used later for the sampler function. Parameters are/\"live on\" `Manifolds`, such as 2D coordinates, real numbers, simplexes, or circles (which are pre-defined, we won't worry about making new ones for now.). In the initialization of the observable, a dictionary of the form `{\"Parameter Name\": Manifold}` is required. Additionally, the parameters $\\beta$ and $R$ are required. An initialization scheme for the parameters is also required, but by default this is set to `kt`.\n",
    "* OPTIONALLY, a plotter function: `SHAPER` is capable of animating its own training process and producing event-by-event displays of shapes fitting onto events. These functions are used to render the shapes in `matplotlib`, which can be used to visualize individual shapes and is very useful for debugging custom shapes. However, this is often not necessary for physics analyses. \n",
    "\n",
    "We will show three custom observables. First, we construct an observable, isotropy, which measures how uniform an event is. Isotropy is unique observable, as it does not require any parameters, making it extremely simple. Second, we will construct the observaled \"N-Point-Ellipsiness\" (This observable *already* exists in commonObservables; this is for illustrative purposes), which measures how much the event looks like ellipses with delta functions at their centers. This has a highly nontrivial parameterization. Finally, we will build a composite observable, \"N-Point-Ellipsiness Plus Pileup\", which combines the previous two observables with the addition operator. For this last observable, we will also show how to construct the optional plotter (note that for N-Point-Ellipsiness, the prebuilt version already has a plotter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyshaper.Manifolds import Coordinates2D, Simplex, PositiveReals, Circle\n",
    "from matplotlib.patches import Rectangle as pltRectangle\n",
    "from matplotlib.patches import Ellipse as pltEllipse\n",
    "\n",
    "\n",
    " \n",
    "#####################\n",
    "# #### Isotropy #####\n",
    "#####################\n",
    "\n",
    "\n",
    "# Sample from a normalized uniform distribution\n",
    "def uniform_sampler(N, param_dict):\n",
    "    points = torch.FloatTensor(N, 2).uniform_(-R, R).to(device)\n",
    "    zs = torch.ones((N,)).to(device) / N\n",
    "    return (points, zs)\n",
    "\n",
    "_isotropy = Observable({}, uniform_sampler, beta = beta, R = R)\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "##### N-Point-Ellipsiness #####\n",
    "###############################\n",
    "\n",
    "# Sample points from N uniform ellipses plus weighted points at their center\n",
    "def point_ellipse_sampler(N, param_dict):\n",
    "\n",
    "    centers = param_dict[\"Points\"].params\n",
    "    num = param_dict[\"Points\"].N\n",
    "    radii1 = param_dict[\"Radius1\"].params\n",
    "    radii2 = param_dict[\"Radius2\"].params\n",
    "    angles = param_dict[\"Angles\"].params\n",
    "    weights = param_dict[\"Weights\"].params\n",
    "\n",
    "    phi = 2 * np.pi * torch.rand(num, N).to(device)\n",
    "    r = torch.sqrt(torch.rand(num, N)).to(device)\n",
    "    points = torch.stack([radii1[:, None] * torch.cos(phi + angles[:, None]), radii2[:, None] * torch.sin(phi + angles[:, None])], axis=1) * r[:, None, :] + centers[:, :, None]\n",
    "    points = torch.cat([point for point in points], dim=1)\n",
    "\n",
    "    # Concatenate and reweight\n",
    "    e = torch.cat([centers, points.T], dim=0)\n",
    "    z1 = torch.cat([weights[i] * torch.ones((1,), device=device) for i in range(num)], dim=0)\n",
    "    z2 = torch.cat([weights[num + i] * torch.ones((N,), device=device) / N for i in range(num)], dim=0)\n",
    "    z = torch.cat([z1, z2], dim=0)\n",
    "    return (e, z)\n",
    "\n",
    "_3pointellipsiness = Observable({\"Points\": Coordinates2D(3), \"Weights\": Simplex(2*3), \"Radius1\": PositiveReals(3, 0), \"Radius2\": PositiveReals(3, 0), \"Angles\": Circle(3, 0)}, point_ellipse_sampler, beta=1, R=R, initializer=\"kt\")\n",
    "\n",
    "\n",
    "################################\n",
    "##### COMPOSITE OBSERVABLE #####\n",
    "################################\n",
    "\n",
    "# First, use the addition operator to join the two previous observables\n",
    "_3pointellipsiness_pileup = _3pointellipsiness + _isotropy\n",
    "\n",
    "# Change the initialization so that the initial relative energies of the two observables is 100-0 (default is 50-50)\n",
    "_3pointellipsiness_pileup.params[\"Joint Weights\"].default_value = torch.tensor([1.0,0.00])\n",
    "\n",
    "# Define the plotter\n",
    "def pileup_plotter(ax, param_dict):\n",
    "\n",
    "    centers = param_dict[\"Points\"].params.clone().detach().numpy()\n",
    "    radii1 = param_dict[\"Radius1\"].params.clone().detach().numpy()\n",
    "    radii2 = param_dict[\"Radius2\"].params.clone().detach().numpy()\n",
    "    angles = param_dict[\"Angles\"].params.clone().detach().numpy()\n",
    "    weights = param_dict[\"Weights\"].params.clone().detach().numpy() * param_dict[\"Joint Weights\"].params.clone().detach().numpy()[0]\n",
    "    num = param_dict[\"Points\"].N\n",
    "    pileup = param_dict[\"Joint Weights\"].params.clone().detach().numpy()[1]\n",
    "\n",
    "    for i in range(num):\n",
    "        # Circle\n",
    "        draw_circle = pltEllipse(centers[i,:], 2*radii1[i], 2*radii2[i], angle = angles[i] * 180 / np.pi, facecolor = \"purple\", edgecolor = \"purple\", alpha = 1.0 * weights[i+num], zorder = 12)\n",
    "        ax.add_artist(draw_circle)\n",
    "\n",
    "        draw_circle = pltEllipse(centers[i,:], 2*radii1[i], 2*radii2[i], angle = angles[i] * 180 / np.pi, facecolor = \"none\", edgecolor = \"purple\", alpha = 0.75)\n",
    "        ax.add_artist(draw_circle)\n",
    "\n",
    "        # Center\n",
    "        ax.scatter(centers[i,0], centers[i,1], color = \"Purple\",  marker = \"x\", s = 2 * weights[i] * 500/np.sum(weights), alpha = 0.75, zorder = 15, lw = 3)\n",
    "        \n",
    "        # Text\n",
    "        eccentricity = np.sqrt(1 - min(radii1[i], radii2[i]) / max(radii1[i], radii2[i]))\n",
    "        if num > 1:\n",
    "            s = \"%d) \" % (num - i)\n",
    "        else:\n",
    "            s = \"\"\n",
    "\n",
    "        plt.text(0.05, 0.10 + 0.05*i, s + r\"Eff. Rad: %.2f, Ecc: %.2f, z$_\\delta$, z$_\\mathcal{O}$: (%.2f, %.2f)\" % (np.sqrt(radii1[i] * radii2[i]), eccentricity, weights[i], weights[i+num], ), fontsize = 18, transform = plt.gca().transAxes)\n",
    "\n",
    "    plt.text(0.05, 0.10 + 0.05*num, r\"z$_{PU}$: %.2f\" % (pileup), fontsize = 18, transform = plt.gca().transAxes)\n",
    "    draw_rect = pltRectangle( (-R*0.9, -R*0.9), 2*R*0.9, 2*R*0.9, angle = 0, facecolor = \"purple\", edgecolor = \"purple\", alpha = 0.50 * pileup)\n",
    "    ax.add_artist(draw_rect)    \n",
    "\n",
    "\n",
    "# Add the plotter\n",
    "_3pointellipsiness_pileup.plotter = pileup_plotter\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAPER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined observables, we can now calculate their values on our dataset using `SHAPER`. There are several options when using `SHAPER`:\n",
    "* `epochs`, `early_stopping`, and `early_stopping_fraction`: The first parameter is the maximum number of epochs the algorithm is allowed to run. The second is how many epochs to wait without improvement to end the algorithm early (25 by default) for each event. If running on many events in a single batch, the last parameter is the fraction of events that need to be considered done (reached `early_stopping` epochs) before the algorithm finished (0.95 by default). It is useful to set this slghtly below 1.00, since there are always a handful of events that take a while to incrementally improve, but these events are \"good enough\" by the time the rest of the other 95% converge. \n",
    "* `N` (default is 100) is passed to each shape observable's sampler function. Typically, this is used to specify how many points should be randomly generated per shape, though this can be used for anything (or not at all) in custom samplers.\n",
    "* `epsilon` (default is 0.001) is the Sinkhorn approximation parameter, and `scaling` (default is 0.9) is the annealing parameter. Both these parameters affect runtime versus precision. If using a GPU, it is highly recommended not to reduce epsilon below 0.001, as machine precision will negatively affect your results.\n",
    "* `lr` (default is .01) is the learning rate for the ADAM optimizer, used to optimize shape parameters. As of `SHAPER v1.0.1`, ADAM is the only supported optimizer.\n",
    "* `verbose` prints to the screen. If a `plot_dictionary` is specified, event displays for each event will be rendered and saved in `matplotlib` after training. If a shape observable has an associated plotter function, this will be used to render the shape on top of the event (useful for debugging and showing example results). If a gif directory is specified, an animation of the entire minimization process will be generated. Note that rendering is resource intensive and is only recommended to do for a small (ten or less) number of events at once.\n",
    "\n",
    "`SHAPER` will process each observable one at a time. For each observable, `SHAPER` will process the entire batch of events in parallel. When running `SHAPER` with the `verbose` option, a new line will print for epoch, and print the percentage of events considered \"done\", as defined by the early stopping procedure. The percentage done will remain at 0% until at least `early_stopping` epochs have passed, after which it will begin to rise. It will continue to rise until either it reaches `early_stopping_fraction` or the total number of epochs reaches `epochs`, after which `SHAPER` will save the lowest EMDs and corresponding parameters for each event, and move on to the next observable. For trivial observables (those with no parameters, or all parameters frozen, such as isotropy), only a single epoch is required.\n",
    "\n",
    "The running time will depend heavily on your computing architecture. If running on an old laptop CPU, this calculation should take 5-10 minutes for 50 events. If running on a GPU, which can be enabled as shown in the Imports section, it will be much faster, and the batch size can be considerably increased for a faster runtime per event.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Collect our observables in one dictionary\n",
    "observables = {}\n",
    "observables[\"Isotropy\"] = _isotropy\n",
    "observables[\"3-Subjettiness\"] = _3subjettiness\n",
    "observables[\"3-Diskiness\"] = _3diskiness\n",
    "observables[\"3-Point-Ellipsiness\"] = _3pointellipsiness\n",
    "observables[\"3-Point-Ellipsiness-Plus-Pileup\"] = _3pointellipsiness_pileup\n",
    "\n",
    "# Initialize SHAPER\n",
    "shaper = Shaper(observables, device)\n",
    "shaper.to(device)\n",
    "\n",
    "\n",
    "# Run SHAPER on a single event, saving a training animation (Note that observables with no plotter will look blank)\n",
    "# NOTE: Need the `imageio` package installed to create gifs -- otheriwse, delete the gif_directory field.\n",
    "plot_dictionary = {\n",
    "    \"plot_directory\" : \"Plots/Test\",\n",
    "    \"gif_directory\" : \"Plots/Test/gifs\",  \n",
    "    \"extension\" : \"png\",\n",
    "    \"title\" : \"SIM Jets\"\n",
    "}\n",
    "emds, params = shaper.calculate(dataset[0], epochs = 500, verbose=True, lr = 0.01, N = 100, scaling = 0.9, epsilon = 0.001, early_stopping= 25, early_stopping_fraction = 0.95, plot_dictionary=plot_dictionary)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Run SHAPER in batches, and save outputs, without plotting (much faster)\n",
    "\n",
    "batch_size = N + 1 # Run for a single batch\n",
    "batches = int(N / batch_size) + 1\n",
    "\n",
    "for batch in range(batches):\n",
    "\n",
    "    print(\"BATCH: %d\" % batch)\n",
    "    start = batch * batch_size\n",
    "    end = (batch + 1) * batch_size\n",
    "\n",
    "    dataset_emds, dataset_params = shaper.calculate(dataset[start:end], epochs = 500, verbose=True, lr = 0.01, N = 50, scaling = 0.9, epsilon = 0.001, early_stopping= 25)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some results, we can plot the observables. We can plot the EMDs, the parameters, or arbitrary functions of them. Below is a generic function useful for histogramming shape parameters, EMDs, or even functions of shape parameters and EMDs. We will use this to plot the minimum and maximum eccentricities of the ellipse observables, as well as the EMDs for each observable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "dataset_emds, dataset_params \n",
    "\n",
    "# Function to make plots of params\n",
    "def plot_observable_param(obs, param, xlim, function = None, xlabel = None, complex_function = None):\n",
    "\n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(8, 8))\n",
    "\n",
    "    bins = 25\n",
    "    sg = []\n",
    "\n",
    "    if param == \"EMD\":\n",
    "        for i in range(N):\n",
    "            sg.append((dataset_emds[obs][i]))\n",
    "\n",
    "    else:\n",
    "        \n",
    "        for i in range(N):\n",
    "\n",
    "            if complex_function is not None:\n",
    "                sg.append(complex_function(dataset_params, obs, i))\n",
    "\n",
    "            elif function is None:\n",
    "\n",
    "                sg.append(dataset_params[obs][i][param])\n",
    "\n",
    "            else:\n",
    "\n",
    "                sg.append(function(dataset_params[obs][i]))\n",
    "            \n",
    "\n",
    "    sg = np.array(sg)\n",
    "    s_counts, s_bins, _ =plt.hist(sg, bins = bins, range = xlim, density = True, lw = 3, color = \"red\", histtype=\"step\", label = \"SIM Jets\")\n",
    "\n",
    "    # for style, fill in hists\n",
    "    plt.hist(sg, bins = bins, range = xlim, density = True, lw = 3, color = \"red\", histtype=\"stepfilled\", alpha = 0.1)\n",
    "\n",
    "\n",
    "    # Cosmetics\n",
    "    legend_elements = [Patch(facecolor= (0,0,1,0.1), edgecolor='b', lw = 2, label='QCD Jets'),\n",
    "                       Patch(facecolor= (1,0,0,0.1), edgecolor='r', lw = 2, label='Top Jets')]\n",
    "\n",
    "\n",
    "    s_max = max(s_counts)\n",
    "    y_lim = s_max * 1.25\n",
    "    plt.ylim(0, y_lim)\n",
    "\n",
    "\n",
    "    plt.xlabel(param)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"%s: %s, PYTHIA8\" % (obs, param), loc = \"right\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def min_eccentricity(param_dict):\n",
    "    a = param_dict[\"Radius1\"]\n",
    "    b = param_dict[\"Radius2\"]\n",
    "    e = np.sqrt(1 - np.nan_to_num(np.minimum(a, b) / np.maximum(a,b)))\n",
    "    return np.amin(e)\n",
    "\n",
    "def max_eccentricity(param_dict):\n",
    "    a = param_dict[\"Radius1\"]\n",
    "    b = param_dict[\"Radius2\"]\n",
    "    e = np.sqrt(1 - np.nan_to_num(np.minimum(a, b) / np.maximum(a,b)))\n",
    "    return np.amax(e)\n",
    "\n",
    "\n",
    "\n",
    "plot_observable_param(\"3-Point-Ellipsiness\", \"Eccentricity\", [0,1.0], min_eccentricity, xlabel = \"Minimum Eccentricity\")\n",
    "plot_observable_param(\"3-Point-Ellipsiness\", \"Eccentricity\", [0,1.0], max_eccentricity, xlabel = \"Maximum Eccentricity\")\n",
    "\n",
    "\n",
    "# Plot all EMDS:\n",
    "for obs in observables:\n",
    "    if obs == \"Isotropy\":\n",
    "        plot_observable_param(obs, \"EMD\", [0, 1.0])\n",
    "    else:\n",
    "        plot_observable_param(obs, \"EMD\", [0, 0.350])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c189c3790ad0f879b11359947e0f24508572947ea4470e1374962daa7aecefe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
